# Medium-large model optimized for A100 40GB
train_file: data/shakespeare.txt
vocab_size: 50257
hidden_size: 768
num_layers: 10
num_thoughts: 8
batch_size: 16
num_epochs: 20
learning_rate: 0.0001
diversity_weight: 0.1
entropy_weight: 0.05
output_dir: outputs/a100_run
run_name: mot_a100_medium_large

# Estimated training time: 3-4 hours
# Model size: ~250M parameters
